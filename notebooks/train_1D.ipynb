{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = np.load(os.path.join(ROOT_DIR, \"datasets\", \"train_1D.npz\"))\n",
    "x_train = data['name1']\n",
    "y_train = data['name2']\n",
    "sym_train = data['name3']\n",
    "\n",
    "data = np.load(os.path.join(ROOT_DIR, \"datasets\", \"val_1D.npz\"))\n",
    "x_val = data['name1']\n",
    "y_val = data['name2']\n",
    "sym_val = data['name3']\n",
    "\n",
    "data = np.load(os.path.join(ROOT_DIR, \"datasets\", \"test_1D.npz\"))\n",
    "x_test = data['name1']\n",
    "y_test = data['name2']\n",
    "sym_test = data['name3']\n",
    "\n",
    "print(x_train.shape, y_train.shape, len(sym_train))\n",
    "print(x_val.shape, y_val.shape, len(sym_val))\n",
    "print(x_test.shape, y_test.shape, len(sym_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation = 'relu', input_dim = x_train.shape[1]))\n",
    "model.add(Dropout(rate = 0.25))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# compile the model - use categorical crossentropy, and the adam optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                optimizer = 'adam',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks.\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "            validation_data=(x_val, y_val),\n",
    "            batch_size = 512, \n",
    "            epochs= 1000, \n",
    "            verbose = 1,\n",
    "            callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def calc_prevalence(y_actual):\n",
    "    return (sum(y_actual)/len(y_actual))\n",
    "\n",
    "\n",
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print('prevalence:%.3f'%calc_prevalence(y_actual))\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity\n",
    "\n",
    "\n",
    "y_train_preds_dense = model.predict_proba(x_train,verbose = 1)\n",
    "y_valid_preds_dense = model.predict_proba(x_val,verbose = 1)\n",
    "y_test_preds_dense = model.predict_proba(x_test,verbose = 1)\n",
    "\n",
    "thresh = (sum(y_train)/len(y_train))[0]\n",
    "print(thresh)\n",
    "\n",
    "print('Train-----------')\n",
    "print_report(y_train, y_train_preds_dense, thresh)\n",
    "print('Valid-----------')\n",
    "print_report(y_val, y_valid_preds_dense, thresh)\n",
    "print('Test-----------')\n",
    "print_report(y_test, y_test_preds_dense, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 256, kernel_size = 5, activation = 'relu', input_shape = (2160,1)))\n",
    "model.add(Dropout(rate = 0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# compile the model - use categorical crossentropy, and the adam optimizer\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "                optimizer = 'adam',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input\n",
    "x_train_cnn = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_val_cnn = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], 1))\n",
    "x_test_cnn = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "print(x_train_cnn.shape)\n",
    "print(x_val_cnn.shape)\n",
    "print(x_test_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks.\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train_cnn, y_train,\n",
    "            validation_data=(x_val_cnn, y_val),\n",
    "            batch_size = 512, \n",
    "            epochs= 1000, \n",
    "            verbose = 1,\n",
    "            callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds_cnn = model.predict_proba(x_train_cnn,verbose = 1)\n",
    "y_valid_preds_cnn = model.predict_proba(x_val_cnn,verbose = 1)\n",
    "y_test_preds_cnn = model.predict_proba(x_test_cnn,verbose = 1)\n",
    "\n",
    "print('Train-----------')\n",
    "print_report(y_train, y_train_preds_cnn, thresh)\n",
    "print('Valid-----------')\n",
    "print_report(y_val, y_valid_preds_cnn, thresh)\n",
    "print('Test-----------')\n",
    "print_report(y_test, y_test_preds_cnn, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fpr_valid_cnn, tpr_valid_cnn, t_valid_cnn = roc_curve(y_val, y_valid_preds_cnn)\n",
    "auc_valid_cnn = roc_auc_score(y_val, y_valid_preds_cnn)\n",
    "\n",
    "fpr_valid_dense, tpr_valid_dense, t_valid_dense = roc_curve(y_val, y_valid_preds_dense)\n",
    "auc_valid_dense = roc_auc_score(y_val, y_valid_preds_dense)\n",
    "\n",
    "plt.plot(fpr_valid_cnn, tpr_valid_cnn, 'g-', label = 'CNN AUC:%.3f'%auc_valid_cnn)\n",
    "plt.plot(fpr_valid_dense, tpr_valid_dense, 'r-', label = 'Dense AUC:%.3f'%auc_valid_dense)\n",
    "\n",
    "plt.plot([0,1],[0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\n",
    "plt.title('Validation Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/gregoiredc/arrhythmia-on-ecg-classification-using-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Convolution1D, MaxPool1D, Flatten, Dropout\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def network():\n",
    "    im_shape=(x_train_cnn.shape[1],1)\n",
    "    inputs_cnn=Input(shape=(im_shape), name='inputs_cnn')\n",
    "    conv1_1=Convolution1D(64, (6), activation='relu', input_shape=im_shape)(inputs_cnn)\n",
    "    conv1_1=BatchNormalization()(conv1_1)\n",
    "    pool1=MaxPool1D(pool_size=(3), strides=(2), padding=\"same\")(conv1_1)\n",
    "    conv2_1=Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool1)\n",
    "    conv2_1=BatchNormalization()(conv2_1)\n",
    "    pool2=MaxPool1D(pool_size=(2), strides=(2), padding=\"same\")(conv2_1)\n",
    "    conv3_1=Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool2)\n",
    "    conv3_1=BatchNormalization()(conv3_1)\n",
    "    pool3=MaxPool1D(pool_size=(2), strides=(2), padding=\"same\")(conv3_1)\n",
    "    flatten=Flatten()(pool3)\n",
    "    dense_end1 = Dense(64, activation='relu')(flatten)\n",
    "    dense_end2 = Dense(32, activation='relu')(dense_end1)\n",
    "    main_output = Dense(1, activation='sigmoid', name='main_output')(dense_end2)\n",
    "    \n",
    "    model = Model(inputs= inputs_cnn, outputs=main_output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = network()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks.\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train_cnn, y_train,\n",
    "            validation_data=(x_val_cnn, y_val),\n",
    "            batch_size = 512, \n",
    "            epochs= 1000, \n",
    "            verbose = 1,\n",
    "            callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds_cnn = model.predict(x_train_cnn,verbose = 1)\n",
    "y_valid_preds_cnn = model.predict(x_val_cnn,verbose = 1)\n",
    "y_test_preds_cnn = model.predict(x_test_cnn,verbose = 1)\n",
    "\n",
    "print('Train-----------')\n",
    "print_report(y_train, y_train_preds_cnn, thresh)\n",
    "print('Valid-----------')\n",
    "print_report(y_val, y_valid_preds_cnn, thresh)\n",
    "print('Test-----------')\n",
    "print_report(y_test, y_test_preds_cnn, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Add, Flatten, Activation\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def network2():\n",
    "    \"\"\"Implementation of https://arxiv.org/pdf/1805.00794.pdf\"\"\"\n",
    "    \n",
    "    n_obs, feature, depth = x_train_cnn.shape\n",
    "    \n",
    "    inp = Input(shape=(feature, depth))\n",
    "    C = Conv1D(filters=32, kernel_size=5, strides=1)(inp)\n",
    "\n",
    "    C11 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(C)\n",
    "    A11 = Activation(\"relu\")(C11)\n",
    "    C12 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A11)\n",
    "    S11 = Add()([C12, C])\n",
    "    A12 = Activation(\"relu\")(S11)\n",
    "    M11 = MaxPooling1D(pool_size=5, strides=2)(A12)\n",
    "\n",
    "\n",
    "    C21 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M11)\n",
    "    A21 = Activation(\"relu\")(C21)\n",
    "    C22 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A21)\n",
    "    S21 = Add()([C22, M11])\n",
    "    A22 = Activation(\"relu\")(S11)\n",
    "    M21 = MaxPooling1D(pool_size=5, strides=2)(A22)\n",
    "\n",
    "\n",
    "    C31 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M21)\n",
    "    A31 = Activation(\"relu\")(C31)\n",
    "    C32 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A31)\n",
    "    S31 = Add()([C32, M21])\n",
    "    A32 = Activation(\"relu\")(S31)\n",
    "    M31 = MaxPooling1D(pool_size=5, strides=2)(A32)\n",
    "\n",
    "\n",
    "    C41 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M31)\n",
    "    A41 = Activation(\"relu\")(C41)\n",
    "    C42 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A41)\n",
    "    S41 = Add()([C42, M31])\n",
    "    A42 = Activation(\"relu\")(S41)\n",
    "    M41 = MaxPooling1D(pool_size=5, strides=2)(A42)\n",
    "\n",
    "\n",
    "    C51 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M41)\n",
    "    A51 = Activation(\"relu\")(C51)\n",
    "    C52 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A51)\n",
    "    S51 = Add()([C52, M41])\n",
    "    A52 = Activation(\"relu\")(S51)\n",
    "    M51 = MaxPooling1D(pool_size=5, strides=2)(A52)\n",
    "\n",
    "    F1 = Flatten()(M51)\n",
    "\n",
    "    D1 = Dense(32)(F1)\n",
    "    A6 = Activation(\"relu\")(D1)\n",
    "    D2 = Dense(32)(A6)\n",
    "    D3 = Dense(1, activation='sigmoid')(D2)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=D3)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = network2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks.\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train_cnn, y_train,\n",
    "            validation_data=(x_val_cnn, y_val),\n",
    "            batch_size = 512, \n",
    "            epochs= 1000, \n",
    "            verbose = 1,\n",
    "            callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds_cnn = model.predict(x_train_cnn,verbose = 1)\n",
    "y_valid_preds_cnn = model.predict(x_val_cnn,verbose = 1)\n",
    "y_test_preds_cnn = model.predict(x_test_cnn,verbose = 1)\n",
    "\n",
    "print('Train-----------')\n",
    "print_report(y_train, y_train_preds_cnn, thresh)\n",
    "print('Valid-----------')\n",
    "print_report(y_val, y_valid_preds_cnn, thresh)\n",
    "print('Test-----------')\n",
    "print_report(y_test, y_test_preds_cnn, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
