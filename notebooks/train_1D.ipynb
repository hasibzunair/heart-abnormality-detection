{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Dense model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60051, 192) (60051, 1)\n",
      "(23925, 192) (23925, 1)\n",
      "(23628, 192) (23628, 1)\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "data = np.load(os.path.join(ROOT_DIR, \"datasets\", \"beats_and_labels.npz\"))\n",
    "x_train = data['name1']\n",
    "y_train = data['name2']\n",
    "x_val = data['name3']\n",
    "y_val = data['name4']\n",
    "x_test = data['name5']\n",
    "y_test = data['name6']\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_val.shape, y_val.shape)\n",
    "print(x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 32)                6176      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 6,209\n",
      "Trainable params: 6,209\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(32, activation = 'relu', input_dim = x_train.shape[1]))\n",
    "model.add(Dropout(rate = 0.25))\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# compile the model - use categorical crossentropy, and the adam optimizer\n",
    "model.compile(loss='binary_crossentropy',\n",
    "                optimizer = 'adam',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60051 samples, validate on 23925 samples\n",
      "Epoch 1/1000\n",
      "60051/60051 [==============================] - 0s 5us/step - loss: 0.3994 - accuracy: 0.8312 - val_loss: 0.3022 - val_accuracy: 0.9102\n",
      "Epoch 2/1000\n",
      "60051/60051 [==============================] - 0s 5us/step - loss: 0.1993 - accuracy: 0.9468 - val_loss: 0.2327 - val_accuracy: 0.9304\n",
      "Epoch 3/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.1372 - accuracy: 0.9687 - val_loss: 0.2255 - val_accuracy: 0.9306\n",
      "Epoch 4/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.1124 - accuracy: 0.9762 - val_loss: 0.2135 - val_accuracy: 0.9287\n",
      "Epoch 5/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0995 - accuracy: 0.9782 - val_loss: 0.2088 - val_accuracy: 0.9322\n",
      "Epoch 6/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0899 - accuracy: 0.9794 - val_loss: 0.1874 - val_accuracy: 0.9436\n",
      "Epoch 7/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0826 - accuracy: 0.9818 - val_loss: 0.1884 - val_accuracy: 0.9419\n",
      "Epoch 8/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0796 - accuracy: 0.9822 - val_loss: 0.1957 - val_accuracy: 0.9395\n",
      "Epoch 9/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0753 - accuracy: 0.9832 - val_loss: 0.1596 - val_accuracy: 0.9587\n",
      "Epoch 10/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0721 - accuracy: 0.9840 - val_loss: 0.1948 - val_accuracy: 0.9408\n",
      "Epoch 11/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0715 - accuracy: 0.9837 - val_loss: 0.1820 - val_accuracy: 0.9514\n",
      "Epoch 12/1000\n",
      "60051/60051 [==============================] - 0s 5us/step - loss: 0.0680 - accuracy: 0.9849 - val_loss: 0.1664 - val_accuracy: 0.9587\n",
      "Epoch 13/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0666 - accuracy: 0.9856 - val_loss: 0.1518 - val_accuracy: 0.9634\n",
      "Epoch 14/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0662 - accuracy: 0.9851 - val_loss: 0.1627 - val_accuracy: 0.9603\n",
      "Epoch 15/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0619 - accuracy: 0.9857 - val_loss: 0.1498 - val_accuracy: 0.9658\n",
      "Epoch 16/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0625 - accuracy: 0.9860 - val_loss: 0.1843 - val_accuracy: 0.9541\n",
      "Epoch 17/1000\n",
      "60051/60051 [==============================] - 0s 5us/step - loss: 0.0600 - accuracy: 0.9862 - val_loss: 0.1816 - val_accuracy: 0.9586\n",
      "Epoch 18/1000\n",
      "60051/60051 [==============================] - 0s 5us/step - loss: 0.0600 - accuracy: 0.9865 - val_loss: 0.1910 - val_accuracy: 0.9551\n",
      "Epoch 19/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0597 - accuracy: 0.9867 - val_loss: 0.1959 - val_accuracy: 0.9493\n",
      "Epoch 20/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0583 - accuracy: 0.9864 - val_loss: 0.1861 - val_accuracy: 0.9510\n",
      "Epoch 21/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0561 - accuracy: 0.9868 - val_loss: 0.1891 - val_accuracy: 0.9533\n",
      "Epoch 22/1000\n",
      "60051/60051 [==============================] - 0s 5us/step - loss: 0.0547 - accuracy: 0.9874 - val_loss: 0.2115 - val_accuracy: 0.9410\n",
      "Epoch 23/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0555 - accuracy: 0.9874 - val_loss: 0.1889 - val_accuracy: 0.9520\n",
      "Epoch 24/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0549 - accuracy: 0.9877 - val_loss: 0.1814 - val_accuracy: 0.9376\n",
      "Epoch 25/1000\n",
      "60051/60051 [==============================] - 0s 4us/step - loss: 0.0530 - accuracy: 0.9876 - val_loss: 0.1940 - val_accuracy: 0.9436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f6a2816b1d0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define callbacks.\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "            validation_data=(x_val, y_val),\n",
    "            batch_size = 512, \n",
    "            epochs= 1000, \n",
    "            verbose = 1,\n",
    "            callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60051/60051 [==============================] - 1s 10us/step\n",
      "23925/23925 [==============================] - 0s 17us/step\n",
      "23628/23628 [==============================] - 0s 13us/step\n",
      "[0.32192636]\n",
      "Train-----------\n",
      "AUC:0.996\n",
      "accuracy:0.988\n",
      "recall:0.977\n",
      "precision:0.987\n",
      "specificity:0.994\n",
      "prevalence:0.322\n",
      " \n",
      "Valid-----------\n",
      "AUC:0.976\n",
      "accuracy:0.953\n",
      "recall:0.935\n",
      "precision:0.911\n",
      "specificity:0.961\n",
      "prevalence:0.299\n",
      " \n",
      "Test-----------\n",
      "AUC:0.828\n",
      "accuracy:0.662\n",
      "recall:0.814\n",
      "precision:0.421\n",
      "specificity:0.608\n",
      "prevalence:0.259\n",
      " \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8279636079621246,\n",
       " 0.6615033011681056,\n",
       " 0.814481856815953,\n",
       " 0.42064832010805336,\n",
       " array([0.60805254]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score\n",
    "\n",
    "\n",
    "def calc_prevalence(y_actual):\n",
    "    return (sum(y_actual)/len(y_actual))\n",
    "\n",
    "\n",
    "def calc_specificity(y_actual, y_pred, thresh):\n",
    "    # calculates specificity\n",
    "    return sum((y_pred < thresh) & (y_actual == 0)) /sum(y_actual ==0)\n",
    "\n",
    "\n",
    "def print_report(y_actual, y_pred, thresh):\n",
    "    auc = roc_auc_score(y_actual, y_pred)\n",
    "    accuracy = accuracy_score(y_actual, (y_pred > thresh))\n",
    "    recall = recall_score(y_actual, (y_pred > thresh))\n",
    "    precision = precision_score(y_actual, (y_pred > thresh))\n",
    "    specificity = calc_specificity(y_actual, y_pred, thresh)\n",
    "    print('AUC:%.3f'%auc)\n",
    "    print('accuracy:%.3f'%accuracy)\n",
    "    print('recall:%.3f'%recall)\n",
    "    print('precision:%.3f'%precision)\n",
    "    print('specificity:%.3f'%specificity)\n",
    "    print('prevalence:%.3f'%calc_prevalence(y_actual))\n",
    "    print(' ')\n",
    "    return auc, accuracy, recall, precision, specificity\n",
    "\n",
    "\n",
    "y_train_preds_dense = model.predict_proba(x_train,verbose = 1)\n",
    "y_valid_preds_dense = model.predict_proba(x_val,verbose = 1)\n",
    "y_test_preds_dense = model.predict_proba(x_test,verbose = 1)\n",
    "\n",
    "thresh = (sum(y_train)/len(y_train))\n",
    "print(thresh)\n",
    "\n",
    "print('Train-----------')\n",
    "print_report(y_train, y_train_preds_dense, thresh)\n",
    "print('Valid-----------')\n",
    "print_report(y_val, y_valid_preds_dense, thresh)\n",
    "print('Test-----------')\n",
    "print_report(y_test, y_test_preds_dense, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 256, kernel_size = 5, activation = 'relu', input_shape = (2160,1)))\n",
    "model.add(Dropout(rate = 0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "# compile the model - use categorical crossentropy, and the adam optimizer\n",
    "model.compile(loss = 'binary_crossentropy',\n",
    "                optimizer = 'adam',\n",
    "                metrics = ['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input\n",
    "x_train_cnn = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "x_val_cnn = np.reshape(x_val, (x_val.shape[0], x_val.shape[1], 1))\n",
    "x_test_cnn = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))\n",
    "\n",
    "print(x_train_cnn.shape)\n",
    "print(x_val_cnn.shape)\n",
    "print(x_test_cnn.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks.\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train_cnn, y_train,\n",
    "            validation_data=(x_val_cnn, y_val),\n",
    "            batch_size = 512, \n",
    "            epochs= 1000, \n",
    "            verbose = 1,\n",
    "            callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds_cnn = model.predict_proba(x_train_cnn,verbose = 1)\n",
    "y_valid_preds_cnn = model.predict_proba(x_val_cnn,verbose = 1)\n",
    "y_test_preds_cnn = model.predict_proba(x_test_cnn,verbose = 1)\n",
    "\n",
    "print('Train-----------')\n",
    "print_report(y_train, y_train_preds_cnn, thresh)\n",
    "print('Valid-----------')\n",
    "print_report(y_val, y_valid_preds_cnn, thresh)\n",
    "print('Test-----------')\n",
    "print_report(y_test, y_test_preds_cnn, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "fpr_valid_cnn, tpr_valid_cnn, t_valid_cnn = roc_curve(y_val, y_valid_preds_cnn)\n",
    "auc_valid_cnn = roc_auc_score(y_val, y_valid_preds_cnn)\n",
    "\n",
    "fpr_valid_dense, tpr_valid_dense, t_valid_dense = roc_curve(y_val, y_valid_preds_dense)\n",
    "auc_valid_dense = roc_auc_score(y_val, y_valid_preds_dense)\n",
    "\n",
    "plt.plot(fpr_valid_cnn, tpr_valid_cnn, 'g-', label = 'CNN AUC:%.3f'%auc_valid_cnn)\n",
    "plt.plot(fpr_valid_dense, tpr_valid_dense, 'r-', label = 'Dense AUC:%.3f'%auc_valid_dense)\n",
    "\n",
    "plt.plot([0,1],[0,1], 'k--')\n",
    "plt.xlabel('FPR')\n",
    "plt.ylabel('TPR')\n",
    "plt.legend(bbox_to_anchor = (1.04,1), loc = 'upper left')\n",
    "plt.title('Validation Set')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/gregoiredc/arrhythmia-on-ecg-classification-using-cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Convolution1D, MaxPool1D, Flatten, Dropout\n",
    "from keras.layers import Input\n",
    "from keras.models import Model\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "def network():\n",
    "    im_shape=(x_train_cnn.shape[1],1)\n",
    "    inputs_cnn=Input(shape=(im_shape), name='inputs_cnn')\n",
    "    conv1_1=Convolution1D(64, (6), activation='relu', input_shape=im_shape)(inputs_cnn)\n",
    "    conv1_1=BatchNormalization()(conv1_1)\n",
    "    pool1=MaxPool1D(pool_size=(3), strides=(2), padding=\"same\")(conv1_1)\n",
    "    conv2_1=Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool1)\n",
    "    conv2_1=BatchNormalization()(conv2_1)\n",
    "    pool2=MaxPool1D(pool_size=(2), strides=(2), padding=\"same\")(conv2_1)\n",
    "    conv3_1=Convolution1D(64, (3), activation='relu', input_shape=im_shape)(pool2)\n",
    "    conv3_1=BatchNormalization()(conv3_1)\n",
    "    pool3=MaxPool1D(pool_size=(2), strides=(2), padding=\"same\")(conv3_1)\n",
    "    flatten=Flatten()(pool3)\n",
    "    dense_end1 = Dense(64, activation='relu')(flatten)\n",
    "    dense_end2 = Dense(32, activation='relu')(dense_end1)\n",
    "    main_output = Dense(1, activation='sigmoid', name='main_output')(dense_end2)\n",
    "    \n",
    "    model = Model(inputs= inputs_cnn, outputs=main_output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "model = network()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks.\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train_cnn, y_train,\n",
    "            validation_data=(x_val_cnn, y_val),\n",
    "            batch_size = 512, \n",
    "            epochs= 1000, \n",
    "            verbose = 1,\n",
    "            callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds_cnn = model.predict(x_train_cnn,verbose = 1)\n",
    "y_valid_preds_cnn = model.predict(x_val_cnn,verbose = 1)\n",
    "y_test_preds_cnn = model.predict(x_test_cnn,verbose = 1)\n",
    "\n",
    "print('Train-----------')\n",
    "print_report(y_train, y_train_preds_cnn, thresh)\n",
    "print('Valid-----------')\n",
    "print_report(y_val, y_valid_preds_cnn, thresh)\n",
    "print('Test-----------')\n",
    "print_report(y_test, y_test_preds_cnn, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling1D, Add, Flatten, Activation\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "def network2():\n",
    "    \"\"\"Implementation of https://arxiv.org/pdf/1805.00794.pdf\"\"\"\n",
    "    \n",
    "    n_obs, feature, depth = x_train_cnn.shape\n",
    "    \n",
    "    inp = Input(shape=(feature, depth))\n",
    "    C = Conv1D(filters=32, kernel_size=5, strides=1)(inp)\n",
    "\n",
    "    C11 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(C)\n",
    "    A11 = Activation(\"relu\")(C11)\n",
    "    C12 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A11)\n",
    "    S11 = Add()([C12, C])\n",
    "    A12 = Activation(\"relu\")(S11)\n",
    "    M11 = MaxPooling1D(pool_size=5, strides=2)(A12)\n",
    "\n",
    "\n",
    "    C21 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M11)\n",
    "    A21 = Activation(\"relu\")(C21)\n",
    "    C22 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A21)\n",
    "    S21 = Add()([C22, M11])\n",
    "    A22 = Activation(\"relu\")(S11)\n",
    "    M21 = MaxPooling1D(pool_size=5, strides=2)(A22)\n",
    "\n",
    "\n",
    "    C31 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M21)\n",
    "    A31 = Activation(\"relu\")(C31)\n",
    "    C32 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A31)\n",
    "    S31 = Add()([C32, M21])\n",
    "    A32 = Activation(\"relu\")(S31)\n",
    "    M31 = MaxPooling1D(pool_size=5, strides=2)(A32)\n",
    "\n",
    "\n",
    "    C41 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M31)\n",
    "    A41 = Activation(\"relu\")(C41)\n",
    "    C42 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A41)\n",
    "    S41 = Add()([C42, M31])\n",
    "    A42 = Activation(\"relu\")(S41)\n",
    "    M41 = MaxPooling1D(pool_size=5, strides=2)(A42)\n",
    "\n",
    "\n",
    "    C51 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(M41)\n",
    "    A51 = Activation(\"relu\")(C51)\n",
    "    C52 = Conv1D(filters=32, kernel_size=5, strides=1, padding='same')(A51)\n",
    "    S51 = Add()([C52, M41])\n",
    "    A52 = Activation(\"relu\")(S51)\n",
    "    M51 = MaxPooling1D(pool_size=5, strides=2)(A52)\n",
    "\n",
    "    F1 = Flatten()(M51)\n",
    "\n",
    "    D1 = Dense(32)(F1)\n",
    "    A6 = Activation(\"relu\")(D1)\n",
    "    D2 = Dense(32)(A6)\n",
    "    D3 = Dense(1, activation='sigmoid')(D2)\n",
    "\n",
    "    model = Model(inputs=inp, outputs=D3)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = network2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks.\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
    "\n",
    "model.fit(x_train_cnn, y_train,\n",
    "            validation_data=(x_val_cnn, y_val),\n",
    "            batch_size = 512, \n",
    "            epochs= 1000, \n",
    "            verbose = 1,\n",
    "            callbacks=[early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds_cnn = model.predict(x_train_cnn,verbose = 1)\n",
    "y_valid_preds_cnn = model.predict(x_val_cnn,verbose = 1)\n",
    "y_test_preds_cnn = model.predict(x_test_cnn,verbose = 1)\n",
    "\n",
    "print('Train-----------')\n",
    "print_report(y_train, y_train_preds_cnn, thresh)\n",
    "print('Valid-----------')\n",
    "print_report(y_val, y_valid_preds_cnn, thresh)\n",
    "print('Test-----------')\n",
    "print_report(y_test, y_test_preds_cnn, thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
