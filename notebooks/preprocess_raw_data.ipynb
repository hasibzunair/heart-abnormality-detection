{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data at patient level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import wfdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "DATA_PATH = os.path.join(ROOT_DIR, \"datasets\", \"mit-bih-arrhythmia-database-1.0.0/\")\n",
    "DATA_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of patients\n",
    "pts = ['100','101','102','103','104','105','106','107',\n",
    "       '108','109','111','112','113','114','115','116',\n",
    "       '117','118','119','121','122','123','124','200',\n",
    "       '201','202','203','205','207','208','209','210',\n",
    "       '212','213','214','215','217','219','220','221',\n",
    "       '222','223','228','230','231','232','233','234']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of nonbeat and abnormal\n",
    "nonbeat = ['[','!',']','x','(',')','p','t','u','`',\n",
    "           '\\'','^','|','~','+','s','T','*','D','=','\"','@','Q','?']\n",
    "abnormal = ['L','R','V','/','A','f','F','j','a','E','J','e','S']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sec = 3\n",
    "fs = 360\n",
    "\n",
    "def load_ecg(file):\n",
    "    \n",
    "    # Load the ECG\n",
    "    # example file: 'mit-bih-arrhythmia-database-1.0.0/101'\n",
    "    record = wfdb.rdrecord(file)\n",
    "    # Load the annotation\n",
    "    annotation = wfdb.rdann(file, 'atr')\n",
    "    \n",
    "    # Extract the signal\n",
    "    p_signal = record.p_signal\n",
    "    \n",
    "    # Verify frequency is 360\n",
    "    assert record.fs == 360, 'sample freq is not 360'\n",
    "    \n",
    "    # Extract symbols and annotation index\n",
    "    atr_sym = annotation.symbol\n",
    "    atr_sample = annotation.sample\n",
    "    \n",
    "    return p_signal, atr_sym, atr_sample\n",
    "\n",
    "\n",
    "def make_dataset(pts, num_sec, fs, abnormal):\n",
    "    # function for making dataset ignoring non-beats\n",
    "    # input:\n",
    "    # pts - list of patients\n",
    "    # num_sec = number of seconds to include before and after the beat\n",
    "    # fs = frequency\n",
    "    # output: \n",
    "    #   X_all = signal (nbeats , num_sec * fs columns)\n",
    "    #   Y_all = binary is abnormal (nbeats, 1)\n",
    "    #   sym_all = beat annotation symbol (nbeats,1)\n",
    "    \n",
    "    # initialize numpy arrays\n",
    "    num_cols = 2*num_sec * fs\n",
    "    X_all = np.zeros((1,num_cols))\n",
    "    Y_all = np.zeros((1,1))\n",
    "    sym_all = []\n",
    "    \n",
    "    # list to keep track of number of beats across patients\n",
    "    max_rows = []\n",
    "    \n",
    "    for pt in pts:\n",
    "        file = DATA_PATH + pt\n",
    "        \n",
    "        p_signal, atr_sym, atr_sample = load_ecg(file)\n",
    "        \n",
    "        # grab the first signal\n",
    "        p_signal = p_signal[:,0]\n",
    "        \n",
    "        # make df to exclude the nonbeats\n",
    "        df_ann = pd.DataFrame({'atr_sym':atr_sym,\n",
    "                              'atr_sample':atr_sample})\n",
    "        df_ann = df_ann.loc[df_ann.atr_sym.isin(abnormal + ['N'])]\n",
    "        \n",
    "        X,Y,sym = build_XY(p_signal,df_ann, num_cols, abnormal)\n",
    "        sym_all = sym_all+sym\n",
    "        max_rows.append(X.shape[0])\n",
    "        X_all = np.append(X_all,X,axis = 0)\n",
    "        Y_all = np.append(Y_all,Y,axis = 0)\n",
    "    # drop the first zero row\n",
    "    X_all = X_all[1:,:]\n",
    "    Y_all = Y_all[1:,:]\n",
    "    \n",
    "    # check sizes make sense\n",
    "    assert np.sum(max_rows) == X_all.shape[0], 'number of X, max_rows rows messed up'\n",
    "    assert Y_all.shape[0] == X_all.shape[0], 'number of X, Y rows messed up'\n",
    "    assert Y_all.shape[0] == len(sym_all), 'number of Y, sym rows messed up'\n",
    "\n",
    "    return X_all, Y_all, sym_all\n",
    "\n",
    "\n",
    "\n",
    "def build_XY(p_signal, df_ann, num_cols, abnormal):\n",
    "    # this function builds the X,Y matrices for each beat\n",
    "    # it also returns the original symbols for Y\n",
    "    \n",
    "    num_rows = len(df_ann)\n",
    "\n",
    "    X = np.zeros((num_rows, num_cols))\n",
    "    Y = np.zeros((num_rows,1))\n",
    "    sym = []\n",
    "    \n",
    "    # keep track of rows\n",
    "    max_row = 0\n",
    "\n",
    "    for atr_sample, atr_sym in zip(df_ann.atr_sample.values,df_ann.atr_sym.values):\n",
    "\n",
    "        left = max([0,(atr_sample - num_sec*fs) ])\n",
    "        right = min([len(p_signal),(atr_sample + num_sec*fs) ])\n",
    "        x = p_signal[left: right]\n",
    "        if len(x) == num_cols:\n",
    "            X[max_row,:] = x\n",
    "            Y[max_row,:] = int(atr_sym in abnormal)\n",
    "            sym.append(atr_sym)\n",
    "            max_row += 1\n",
    "    X = X[:max_row,:]\n",
    "    Y = Y[:max_row,:]\n",
    "    return X,Y,sym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "pts_train = random.sample(pts, 28)\n",
    "\n",
    "pts_dev = [pt for pt in pts if pt not in pts_train]\n",
    "\n",
    "pts_val = random.sample(pts_dev, 10)\n",
    "pts_test = [pt for pt in pts_dev if pt not in pts_val]\n",
    "\n",
    "print(len(pts_train), len(pts_val), len(pts_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pts_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for overlap\n",
    "def lists_overlap(a, b):\n",
    "    for i in a:\n",
    "        if i in b:\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lists_overlap(pts_train, pts_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train, sym_train = make_dataset(pts_train, num_sec, fs, abnormal)\n",
    "x_val, y_val, sym_val = make_dataset(pts_val, num_sec, fs, abnormal)\n",
    "x_test, y_test, sym_test = make_dataset(pts_test, num_sec, fs, abnormal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train.shape, y_train.shape, len(sym_train))\n",
    "print(x_val.shape, y_val.shape, len(sym_val))\n",
    "print(x_test.shape, y_test.shape, len(sym_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(os.path.join(ROOT_DIR, \"datasets\", \"train_1D.npz\"), \n",
    "         name1=x_train, name2=y_train, name3=sym_train)\n",
    "\n",
    "np.savez(os.path.join(ROOT_DIR, \"datasets\", \"val_1D.npz\"), \n",
    "         name1=x_val, name2=y_val, name3=sym_val)\n",
    "\n",
    "np.savez(os.path.join(ROOT_DIR, \"datasets\", \"test_1D.npz\"), \n",
    "         name1=x_test, name2=y_test, name3=sym_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = np.load(os.path.join(ROOT_DIR, \"datasets\", \"train_1D.npz\"))\n",
    "x = data['name1']\n",
    "y = data['name2']\n",
    "sym = data['name3']\n",
    "\n",
    "x.shape, y.shape, sym.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
